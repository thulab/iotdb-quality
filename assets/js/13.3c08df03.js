(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{383:function(t,e,a){"use strict";a.r(e);var n=a(45),s=Object(n.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"tsclean-iotdb"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tsclean-iotdb"}},[t._v("#")]),t._v(" TsClean-IoTDB")]),t._v(" "),a("p",[t._v("Language: English | "),a("RouterLink",{attrs:{to:"/README_zh.html"}},[t._v("中文")])],1),t._v(" "),a("h2",{attrs:{id:"introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[t._v("#")]),t._v(" Introduction")]),t._v(" "),a("p",[t._v("TsClean is developed independently by the National Engineering Laboratory for Big Data Software, Tsinghua University. It is a data quality system of international advanced level. It focuses on data quality and provides a solid foundation for the application of industrial big data. It has been widely used in many industrial scenes and well received by users.")]),t._v(" "),a("p",[t._v("This project is User Defined Functions (UDF) of "),a("a",{attrs:{href:"https://github.com/apache/iotdb",target:"_blank",rel:"noopener noreferrer"}},[t._v("Apache IoTDB"),a("OutboundLink")],1),t._v(". It implements many key functions of TsClean including data quality indicator calculation, value filling, value repairing, etc.")]),t._v(" "),a("h2",{attrs:{id:"quick-start"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#quick-start"}},[t._v("#")]),t._v(" Quick Start")]),t._v(" "),a("ol",[a("li",[t._v("Package this project into a JAR with all of its dependencies or directly "),a("a",{attrs:{href:"proguard-target/udf-tsclean-0.1.0-jar-with-dependencies.jar"}},[t._v("download it")]),t._v(".")]),t._v(" "),a("li",[t._v("Copy the JAR package to "),a("code",[t._v("ext\\udf")]),t._v(" under the directory of IoTDB server.")]),t._v(" "),a("li",[t._v("Register the UDFs with the following SQL statements in IoTDB:")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" completeness "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" “cn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("thu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dquality"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("udf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UDTFCompleteness”\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" consistency "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" “cn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("thu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dquality"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("udf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UDTFConsistency”\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" timeliness "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" “cn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("thu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dquality"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("udf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UDTFTimeliness”\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" validity "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" “cn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("thu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dquality"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("udf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UDTFValidity”\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" previousfill "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" “cn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("thu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dquality"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("udf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UDTFPreviousFill”\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" linearfill "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" “cn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("thu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dquality"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("udf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UDTFLinearFill”\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" lsgreedyrepair "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" “cn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("thu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dquality"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("udf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UDTFLsGreedyRepair”\n")])])]),t._v(" "),a("h2",{attrs:{id:"introductions-of-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introductions-of-functions"}},[t._v("#")]),t._v(" Introductions of Functions")]),t._v(" "),a("h3",{attrs:{id:"functions-about-data-quality-indicators"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#functions-about-data-quality-indicators"}},[t._v("#")]),t._v(" Functions about data quality indicators")]),t._v(" "),a("p",[t._v("For time series, we develop 4 data quality indicators: completeness, consistency, timeliness and validity. The UDFs to calculate these indicators are as follows:")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}},[t._v("Name")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Type of Input Series")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Parameters")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Type of Output Series")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Description")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("COMPLETENESS")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("INT32 / INT64 / FLOAT / DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[a("code",[t._v("window")]),t._v(": The number of data points in each window. The number of data points in the last window may be less than it. By default, all input data belongs to the same window.")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("The input series are divided into several continuous and non overlapping windows. The timestamp of the first data point and the completeness of each window will be output.")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("CONSISTENCY")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("INT32 / INT64 / FLOAT / DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[a("code",[t._v("window")]),t._v(": The number of data points in each window. The number of data points in the last window may be less than it. By default, all input data belongs to the same window.")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("The input series are divided into several continuous and non overlapping windows. The timestamp of the first data point and the consistency of each window will be output.")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("TIMELINESS")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("INT32 / INT64 / FLOAT / DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[a("code",[t._v("window")]),t._v(": The number of data points in each window. The number of data points in the last window may be less than it. By default, all input data belongs to the same window.")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("The input series are divided into several continuous and non overlapping windows. The timestamp of the first data point and the timeliness of each window will be output.")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("VALIDITY")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("INT32 / INT64 / FLOAT / DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[a("code",[t._v("window")]),t._v(": The number of data points in each window. The number of data points in the last window may be less than it. By default, all input data belongs to the same window.")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("The input series are divided into several continuous and non overlapping windows. The timestamp of the first data point and the validity of each window will be output.")])])])]),t._v(" "),a("p",[t._v("Example:")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("completeness"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("consistency"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("timeliness"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("validity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("d1 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("time")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("00")]),t._v(":"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("00")]),t._v(":"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("\n")])])]),a("p",[t._v("Result:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("+-----------------------------+---------------+-----------------------------+----------------------------+---------------------------+-------------------------+\n|                         Time|root.test.d1.s1|completeness(root.test.d1.s1)|consistency(root.test.d1.s1)|timeliness(root.test.d1.s1)|validity(root.test.d1.s1)|\n+-----------------------------+---------------+-----------------------------+----------------------------+---------------------------+-------------------------+\n|2020-01-01T00:00:02.000+08:00|          100.0|                        0.875|          0.9333333333333333|         0.9333333333333333|       0.8833333333333333|\n|2020-01-01T00:00:03.000+08:00|          101.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:04.000+08:00|          102.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:06.000+08:00|          104.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:08.000+08:00|          126.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:10.000+08:00|          108.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:14.000+08:00|          112.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:15.000+08:00|          113.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:16.000+08:00|          114.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:18.000+08:00|          116.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:20.000+08:00|          118.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:22.000+08:00|          120.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:26.000+08:00|          124.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:28.000+08:00|          126.0|                         null|                        null|                       null|                     null|\n|2020-01-01T00:00:30.000+08:00|            NaN|                         null|                        null|                       null|                     null|\n+-----------------------------+---------------+-----------------------------+----------------------------+---------------------------+-------------------------+\nTotal line number = 15\nIt costs 0.212s\n")])])]),a("h3",{attrs:{id:"functions-about-value-filling"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#functions-about-value-filling"}},[t._v("#")]),t._v(" Functions about value filling")]),t._v(" "),a("p",[t._v("We develop some value filling functions for time series. Their UDFs are as follows:")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}},[t._v("Name")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Type of Input Series")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Parameters")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Type of Output Series")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Description")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("PREVIOUSFILL")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("FLOAT / DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[a("code",[t._v("beforeRange")]),t._v(": The valid range of filling method. Filling works when the time difference between previous non-"),a("code",[t._v("NaN")]),t._v(" point and this point is not more than it. By default, it's infinity.")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Same type as the input series")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("The "),a("code",[t._v("NaN")]),t._v(" points in the input series will be filled with the value of the previous non-"),a("code",[t._v("NaN")]),t._v(" point. The new series will be output.")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("LINEARFILL")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("FLOAT / DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[a("code",[t._v("beforeRange")]),t._v(": The valid range of filling method. Filling works when the time difference between previous non-"),a("code",[t._v("NaN")]),t._v(" point and this point is not more than it. By default, it's infinity."),a("br"),t._v(" "),a("code",[t._v("afterRange")]),t._v(": The valid range of filling method. Filling works when the time difference between next non-"),a("code",[t._v("NaN")]),t._v(" point and this point is not more than it. By default, it's infinity.")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Same type as the input series")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("The "),a("code",[t._v("NaN")]),t._v(" points in the input series will be filled with the value of the previous and next non-"),a("code",[t._v("NaN")]),t._v(" point by linear interpolation. The new series will be output.")])])])]),t._v(" "),a("p",[t._v("Example:")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" s2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("previousfill"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"beforeRange"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1000"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("linearfill"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"beforeRange"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1000"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"afterRange"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1000"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("d1 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("time")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("00")]),t._v(":"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("00")]),t._v(":"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("\n")])])]),a("p",[t._v("Result:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('+-----------------------------+---------------+---------------------------------------------------+----------------------------------------------------------------------+\n|                         Time|root.test.d1.s2|previousfill(root.test.d1.s2, "beforeRange"="1000")|linearfill(root.test.d1.s2, "beforeRange"="1000", "afterRange"="1000")|\n+-----------------------------+---------------+---------------------------------------------------+----------------------------------------------------------------------+\n|2020-01-01T00:00:00.000+08:00|            NaN|                                                NaN|                                                                   NaN|\n|2020-01-01T00:00:01.000+08:00|          120.0|                                              120.0|                                                                 120.0|\n|2020-01-01T00:00:02.000+08:00|          120.0|                                              120.0|                                                                 120.0|\n|2020-01-01T00:00:04.000+08:00|            NaN|                                                NaN|                                                                   NaN|\n|2020-01-01T00:00:05.000+08:00|          130.0|                                              130.0|                                                                 130.0|\n|2020-01-01T00:00:06.000+08:00|            NaN|                                              130.0|                                                                 135.0|\n|2020-01-01T00:00:07.000+08:00|          140.0|                                              140.0|                                                                 140.0|\n+-----------------------------+---------------+---------------------------------------------------+----------------------------------------------------------------------+\nTotal line number = 7\nIt costs 0.421s\n')])])]),a("h3",{attrs:{id:"functions-about-value-repairing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#functions-about-value-repairing"}},[t._v("#")]),t._v(" Functions about value repairing")]),t._v(" "),a("p",[t._v("There may be some outliers in time series. We develop some value repairing functions to repair these outliers. Their UDFs are as follows:")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}},[t._v("Name")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Type of Input Series")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Parameters")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Type of Output Series")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Description")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("SCREENREPAIR")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("INT32 / INT64 / FLOAT / DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[a("code",[t._v("minSpeed")]),t._v(": Speed threshold. Speeds below it will be regarded as outliers. By default, it is the median minus 3 times of median absolute deviation. "),a("br"),t._v(" "),a("code",[t._v("maxSpeed")]),t._v(": Speed threshold. Speeds above it will be regarded as outliers. By default, it is the median plus 3 times of median absolute deviation.")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Same type as the input series")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("The outliers will be repaired by Screen method based on speed constraints. The new series will be output. Before repairing, "),a("code",[t._v("NaN")]),t._v(" will be filled with linear interpolation.")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("LSGREEDYREPAIR")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("INT32 / INT64 / FLOAT / DOUBLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[a("code",[t._v("center")]),t._v(": Center of the Gaussian distribution of speed changes. By default, it is 0. "),a("br"),t._v(" "),a("code",[t._v("sigma")]),t._v(": Standard deviation of the Gaussian distribution of speed changes. By default, it is the median absolute deviation.")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Same type as the input series")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("The outliers will be repaired by LsGreedy method based on speed change likelihoods. The new series will be output. Before repairing, "),a("code",[t._v("NaN")]),t._v(" will be filled with linear interpolation.")])])])]),t._v(" "),a("p",[t._v("Example:")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("screenrepair"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("lsgreedyrepair"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("d1 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("time")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("01")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("00")]),t._v(":"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("00")]),t._v(":"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("\n")])])]),a("p",[t._v("Result:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("+-----------------------------+---------------+-----------------------------+-------------------------------+\n|                         Time|root.test.d1.s1|screenrepair(root.test.d1.s1)|lsgreedyrepair(root.test.d1.s1)|\n+-----------------------------+---------------+-----------------------------+-------------------------------+\n|2020-01-01T00:00:02.000+08:00|          100.0|                        100.0|                          100.0|\n|2020-01-01T00:00:03.000+08:00|          101.0|                        101.0|                          101.0|\n|2020-01-01T00:00:04.000+08:00|          102.0|                        102.0|                          102.0|\n|2020-01-01T00:00:06.000+08:00|          104.0|                        104.0|                          104.0|\n|2020-01-01T00:00:08.000+08:00|          126.0|                        106.0|                          106.0|\n|2020-01-01T00:00:10.000+08:00|          108.0|                        108.0|                          108.0|\n|2020-01-01T00:00:14.000+08:00|          112.0|                        112.0|                          112.0|\n|2020-01-01T00:00:15.000+08:00|          113.0|                        113.0|                          113.0|\n|2020-01-01T00:00:16.000+08:00|          114.0|                        114.0|                          114.0|\n|2020-01-01T00:00:18.000+08:00|          116.0|                        116.0|                          116.0|\n|2020-01-01T00:00:20.000+08:00|          118.0|                        118.0|                          118.0|\n|2020-01-01T00:00:22.000+08:00|          120.0|                        120.0|                          120.0|\n|2020-01-01T00:00:26.000+08:00|          124.0|                        124.0|                          124.0|\n|2020-01-01T00:00:28.000+08:00|          126.0|                        126.0|                          126.0|\n|2020-01-01T00:00:30.000+08:00|            NaN|                        128.0|                          128.0|\n+-----------------------------+---------------+-----------------------------+-------------------------------+\nTotal line number = 15\nIt costs 0.766s\n")])])]),a("h2",{attrs:{id:"implementations-of-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#implementations-of-functions"}},[t._v("#")]),t._v(" Implementations of Functions")]),t._v(" "),a("h3",{attrs:{id:"data-quality-indicators"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#data-quality-indicators"}},[t._v("#")]),t._v(" Data quality indicators")]),t._v(" "),a("p",[t._v("For data quality of time series, we develop the following 4 indicators. Each indicator includes one or more exceptions:")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}},[t._v("Completeness")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Consistency")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Timeliness")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Validity")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("Data miss exception")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Redundancy exception")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Late exception")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Value exception")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("Null exception")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}}),t._v(" "),a("td",{staticStyle:{"text-align":"center"}}),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Variation exception")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("Special value exception")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}}),t._v(" "),a("td",{staticStyle:{"text-align":"center"}}),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Speed exception")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}}),t._v(" "),a("td",{staticStyle:{"text-align":"center"}}),t._v(" "),a("td",{staticStyle:{"text-align":"center"}}),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("Speed change exception")])])])]),t._v(" "),a("p",[a("strong",[t._v("Completeness")]),t._v(" is calculated as follows:")]),t._v(" "),a("p",[t._v("Completeness = 1 - (N"),a("sub",[t._v("null")]),t._v(" + N"),a("sub",[t._v("special")]),t._v(" + N"),a("sub",[t._v("miss")]),t._v(") / (N + N"),a("sub",[t._v("miss")]),t._v(")")]),t._v(" "),a("p",[t._v("where N is the total number of data points in time series, N"),a("sub",[t._v("null")]),t._v(" is the number of points with null value, N"),a("sub",[t._v("special")]),t._v(" is the number of points with specail value and N"),a("sub",[t._v("miss")]),t._v(" is the number of missing points.")]),t._v(" "),a("p",[a("strong",[t._v("Consistency")]),t._v(" is calculated as follows:")]),t._v(" "),a("p",[t._v("Consistency = 1 - N"),a("sub",[t._v("redundancy")]),t._v(" / N")]),t._v(" "),a("p",[t._v("where N is the total number of data points in time series and N"),a("sub",[t._v("redundancy")]),t._v(" is the number of redundant points.")]),t._v(" "),a("p",[a("strong",[t._v("Timeliness")]),t._v(" is calculated as follows:")]),t._v(" "),a("p",[t._v("Timeliness = 1 - N"),a("sub",[t._v("late")]),t._v(" / N")]),t._v(" "),a("p",[t._v("where N is the total number of data points in time series and N"),a("sub",[t._v("late")]),t._v(" is the number of late points.")]),t._v(" "),a("p",[a("strong",[t._v("Validity")]),t._v(" is calculated as follows:")]),t._v(" "),a("p",[t._v("Validity = 1 - (N"),a("sub",[t._v("value")]),t._v(" + N"),a("sub",[t._v("variation")]),t._v(" + N"),a("sub",[t._v("speed")]),t._v(" + N"),a("sub",[t._v("speedchange")]),t._v(") / (4 * N)")]),t._v(" "),a("p",[t._v("where N is the total number of data points in time series, N"),a("sub",[t._v("value")]),t._v(" is the number of points breaking value constraint, N"),a("sub",[t._v("variation")]),t._v(" is the number of points breaking variation constraint, N"),a("sub",[t._v("speed")]),t._v(" is the number of points breaking speed constraint and N"),a("sub",[t._v("speedchange")]),t._v(" is the number of points breaking speed change constraint. Significantly, a single data point may break multiple constraints.")]),t._v(" "),a("p",[t._v("Base on the original values and their timestamps, the variaiton, speed and speed change can be calculated as follows:")]),t._v(" "),a("p",[t._v("variation"),a("sub",[t._v("i")]),t._v(" = value"),a("sub",[t._v("i+1")]),t._v(" - value"),a("sub",[t._v("i")])]),t._v(" "),a("p",[t._v("speed"),a("sub",[t._v("i")]),t._v(" = (value"),a("sub",[t._v("i+1")]),t._v(" - value"),a("sub",[t._v("i")]),t._v(") / (time"),a("sub",[t._v("i+1")]),t._v(" - time"),a("sub",[t._v("i")]),t._v(")")]),t._v(" "),a("p",[t._v("speedchange"),a("sub",[t._v("i")]),t._v(" = speed"),a("sub",[t._v("i+1")]),t._v(" - speed"),a("sub",[t._v("i")])]),t._v(" "),a("p",[t._v("For series x, when the difference between x"),a("sub",[t._v("i")]),t._v(" and the median of x is more than 3 times of the median absolute deviation (MAD, a constant 1.4826 is multipled for asymptotic normality) of x, the constraint is broken, i.e.")]),t._v(" "),a("p",[t._v("abs(x"),a("sub",[t._v("i")]),t._v(" - mid(x)) > 3 * mad(x)")]),t._v(" "),a("h3",{attrs:{id:"data-filling-methods"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#data-filling-methods"}},[t._v("#")]),t._v(" Data filling methods")]),t._v(" "),a("p",[t._v("Suppose the timestamp of the data point is t and the previous and next non-"),a("code",[t._v("NaN")]),t._v(" data points are (t"),a("sub",[t._v("1")]),t._v(",v"),a("sub",[t._v("1")]),t._v(") and (t"),a("sub",[t._v("2")]),t._v(",v"),a("sub",[t._v("2")]),t._v(") respectively.\nThus, filling with "),a("strong",[t._v("Previous")]),t._v(" method, the value is")]),t._v(" "),a("p",[t._v("v = v"),a("sub",[t._v("1")])]),t._v(" "),a("p",[t._v("Filling with "),a("strong",[t._v("Linear")]),t._v(" method, the value is")]),t._v(" "),a("p",[t._v("v = v"),a("sub",[t._v("1")]),t._v(" + (t - t"),a("sub",[t._v("1")]),t._v(") * (v"),a("sub",[t._v("2")]),t._v(" - v"),a("sub",[t._v("1")]),t._v(") / (t"),a("sub",[t._v("2")]),t._v(" - t"),a("sub",[t._v("1")]),t._v(")")]),t._v(" "),a("h3",{attrs:{id:"data-repairing-methods"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#data-repairing-methods"}},[t._v("#")]),t._v(" Data repairing methods")]),t._v(" "),a("p",[a("strong",[t._v("Screen")]),t._v(" method is based on speed constraints. Its key idea is making the whole time series meet the speed constraints while repairing as few data points as possible.\nDue to the complexity of glocal optimum, the constraints are relaxed into a sliding window with the combination of candidate range and median principle.\nThe detailed algorithm is shown in "),a("a",{attrs:{href:"https://dl.acm.org/doi/10.1145/2723372.2723730",target:"_blank",rel:"noopener noreferrer"}},[t._v("SIGMOD'15-Screen"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("p",[a("strong",[t._v("LsGreedy")]),t._v(" method is based on speed change likelihoods. Its key idea is modeling the distribution of speed changes and maximizing the likelihood function.\nGenerally, the model is Gaussian. In order to reduce the computational complexity, a greedy algorithm is used.\nDecreasing the difference between the speed change and the center is equal to increasing the likelihood function.\nKept in a max heap, the data point with the maximum speed change will be modified to make the speed change closer to the center.\nThe algorithm terminates when no speed change difference is larger than 3 times of standard deviation.\nThe detailed algorithm is shown in "),a("a",{attrs:{href:"https://dl.acm.org/doi/10.1145/2882903.2915233",target:"_blank",rel:"noopener noreferrer"}},[t._v("SIGMOD'16-Sequential"),a("OutboundLink")],1),t._v(".")])])}),[],!1,null,null,null);e.default=s.exports}}]);